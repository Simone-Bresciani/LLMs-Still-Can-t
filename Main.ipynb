{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluate_task import Task\n",
        "from evaluate_task import evaluate_multiple_choice_task \n",
        "from evaluate_task import evaluate_free_response_task\n",
        "\n",
        "GPT3_5 = \"gpt-3.5-turbo-1106\"\n",
        "GPT4 = \"gpt-4-0125-preview\"\n",
        "\n",
        "anachronism = Task('multiple_choice',\n",
        "                   'data/task_anachronisms.json',\n",
        "                   'Does the following sentence contain non-contemporaneous (anachronistic) elements?.')\n",
        "logical_sequence = Task('multiple_choice',\n",
        "                        'data/task_logical_sequence.json',\n",
        "                        \"Identify the correct chronological or sequential order of items in a list.\")\n",
        "color_HCL = Task('multiple_choice', 'data/task_color_HCL.json',\"\")\n",
        "color_RGB = Task('multiple_choice', 'data/task_color_RGB.json',\"\")\n",
        "color_HEX = Task('multiple_choice', 'data/task_color_HEX.json',\"\")\n",
        "color_HSL = Task('multiple_choice', 'data/task_color_HSL.json',\"\")\n",
        "matrixshapes = Task('free_response',\n",
        "                    'data/task_matrixshapes.json',\n",
        "                    \"Keep track of matrix shapes through various transformations.\")\n",
        "operators = Task('free_response',\n",
        "                    'data/task_operators.json',\n",
        "                    \"Given the definition of the op operator, compute the result.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anachronism.evaluate(GPT3_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "# start a new wandb run to track this script\n",
        "wandb.init(project=\"LLMs-Still-Can-t\",config={\n",
        "    \"model\": GPT4,\n",
        "    \"dataset\": anachronism.json_string,\n",
        "    \"shot\": 0})\n",
        "\n",
        "# evaluate the task n times\n",
        "for i in range(1):\n",
        "    acc , df = anachronism.evaluate(wandb.config.model)\n",
        "    wandb.log({\"System Prompt\": anachronism.system_prompt, \n",
        "                \"Name\":f\"Baseline [{anachronism.json_string}]\", \n",
        "                \"accuracy\": acc, \n",
        "                \"examples\": wandb.Table(dataframe=df)})\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
