{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluate_task import evaluate_multiple_choice_task \n",
        "from evaluate_task import evaluate_free_response_task\n",
        "GPT3_5 = \"gpt-3.5-turbo-1106\"\n",
        "GPT4 = \"gpt-4-0125-preview\"\n",
        "\n",
        "#Task 1 - multiple choice\n",
        "task_anachronisms = 'data/task_anachronisms.json'\n",
        "sys_anachronism = \"Does the following sentence contain non-contemporaneous (anachronistic) elements?.\"\n",
        "\n",
        "#Task 2 - multiple choice\n",
        "task_logical_sequence = 'data/task_logical_sequence.json'\n",
        "sys_logical_sequence = \"Identify the correct chronological or sequential order of items in a list.\"\n",
        "\n",
        "#Task 3 - multiple choice\n",
        "task_color_HCL = 'data/task_color_HCL.json'\n",
        "task_color_RGB = 'data/task_color_RGB.json'\n",
        "task_color_HEX = 'data/task_color_HEX.json'\n",
        "task_color_HSL = 'data/task_color_HSL.json'\n",
        "\n",
        "#Task 4 - free choice\n",
        "task_matrixshapes = 'data/task_matrixshapes.json'\n",
        "sys_matrixshapes = \"Keep track of matrix shapes through various transformations.\"\n",
        "\n",
        "#Task 5 - free choice\n",
        "task_operators = 'data/task_operators.json'\n",
        "sys_operators = \"Given the definition of the op operator, compute the result.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(f\"Accuracy#1: {evaluate_multiple_choice_task(task_anachronisms, sys_anachronism, GPT3_5)}\")\n",
        "#print(f\"Accuracy#2: {evaluate_multiple_choice_task(task_logical_sequence, sys_logical_sequence, GPT3_5)}\")\n",
        "print(f\"Accuracy#3.1: {evaluate_multiple_choice_task(task_color_HCL, \"\", GPT3_5)}\")\n",
        "print(f\"Accuracy#3.2: {evaluate_multiple_choice_task(task_color_RGB, \"\", GPT3_5)}\")\n",
        "print(f\"Accuracy#3.3: {evaluate_multiple_choice_task(task_color_HEX, \"\", GPT3_5)}\")\n",
        "print(f\"Accuracy#3.4: {evaluate_multiple_choice_task(task_color_HSL, \"\", GPT3_5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy#4: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy#4: {evaluate_free_response_task(task_matrixshapes, sys_matrixshapes, GPT3_5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "# start a new wandb run to track this script\n",
        "wandb.init(project=\"LLMs-Still-Can-t\",config={\n",
        "    \"model\": GPT3_5,\n",
        "    \"dataset\": task_anachronisms,\n",
        "    \"shot\": 0})\n",
        "\n",
        "# evaluate the task\n",
        "acc = evaluate_multiple_choice_task(task_anachronisms, sys_anachronism, GPT3_5)\n",
        "\n",
        "\n",
        "# log the final accuracy back to wandb, and end the run\n",
        "wandb.log({\"acc\": acc, \"results\": }) \n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
