{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from shrink_dataset import extract_datasets\n",
        "#extract_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "from evaluate_task import Task\n",
        "GPT3_5 = \"gpt-3.5-turbo-0125\" #metti la preview\n",
        "GPT4 = \"gpt-4-0125-preview\"\n",
        "\n",
        "anachronism = Task('multiple_choice',\n",
        "                   'datasets/task_anachronisms.json',\n",
        "                   'Does the following sentence contain non-contemporaneous (anachronistic) elements?.')\n",
        "logical_sequence = Task('multiple_choice',\n",
        "                        'datasets/task_logical_sequence.json',\n",
        "                        \"Identify the correct chronological or sequential order of items in a list.\")\n",
        "color_HCL = Task('multiple_choice', 'datasets/task_color_HCL.json',\"\")\n",
        "color_RGB = Task('multiple_choice', 'datasets/task_color_RGB.json',\"\")\n",
        "color_HEX = Task('multiple_choice', 'datasets/task_color_HEX.json',\"\")\n",
        "color_HSL = Task('multiple_choice', 'datasets/task_color_HSL.json',\"\")\n",
        "matrixshapes = Task('free_response',\n",
        "                    'datasets/task_matrixshapes.json',\n",
        "                    \"Compute the final matrix shape after the given operations are performed.\")\n",
        "operators = Task('free_response',\n",
        "                    'datasets/task_operators.json',\n",
        "                    \"Given the definition of the op operator, compute the result.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#BASELINE\n",
        "\n",
        "MULTIPLE_CHOICE_SUFFIX = \"Just repeat the answer you choose.\"\n",
        "FREE_RESPONSE_SUFFIX = \"Please don't show me the steps, i just want to see the final result in one single line.\"\n",
        "\n",
        "for task in [matrixshapes]:\n",
        "\n",
        "    wandb.init(project=\"LLMs-Still-Can-t\",config={\"model\": GPT4,\"shots\": 0})\n",
        "\n",
        "    suffix = MULTIPLE_CHOICE_SUFFIX if task.type == 'multiple_choice' else FREE_RESPONSE_SUFFIX\n",
        "    acc , df = task.evaluate(wandb.config.model, suffix, wandb.config.shots)\n",
        "\n",
        "    wandb.log({ \"accuracy\": acc, \"examples\": wandb.Table(dataframe=df)})\n",
        "\n",
        "    wandb.run.summary[\"system_prompt\"] = task.system_prompt + suffix\n",
        "    wandb.run.summary[\"model\"] = wandb.config.model\n",
        "    wandb.run.summary[\"shots\"] = wandb.config.shots\n",
        "    wandb.run.summary[\"name\"] = f\"Baseline [{task.json_string}]\"\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#WITH EXPLANATION\n",
        "\n",
        "MULTIPLE_CHOICE_SUFFIX = \"In the first line you answer repeating the answer you choose, in the second line explain your answer in 20 words.\"\n",
        "FREE_RESPONSE_SUFFIX = \"In the first line you answer just the result, in the second line explain your answer in 20 words.\"\n",
        "\n",
        "\n",
        "for task in [matrixshapes]:\n",
        "\n",
        "    wandb.init(project=\"LLMs-Still-Can-t\",config={\"model\": GPT3_5,\"shots\": 0})\n",
        "\n",
        "    suffix = MULTIPLE_CHOICE_SUFFIX if task.type == 'multiple_choice' else FREE_RESPONSE_SUFFIX\n",
        "    acc , df = task.evaluate(wandb.config.model, suffix, wandb.config.shots)\n",
        "\n",
        "    wandb.log({ \"accuracy\": acc, \"examples\": wandb.Table(dataframe=df)})\n",
        "\n",
        "    wandb.run.summary[\"system_prompt\"] = task.system_prompt + suffix\n",
        "    wandb.run.summary[\"model\"] = wandb.config.model\n",
        "    wandb.run.summary[\"shots\"] = wandb.config.shots\n",
        "    wandb.run.summary[\"name\"] = f\"Explain [{task.json_string}]\"\n",
        "\n",
        "    wandb.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#baseline\n",
        "#explain\n",
        "#chain of thoughts (che valga per tutte le task)\n",
        "#few-shots(1 e 5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
